# Model Traces 

The **Model Traces** feature offers a comprehensive view of model performance across runs, enabling tracking of request-level data and key metrics. With features for filtering, searching, and exporting data, it supports precise analysis and troubleshooting, ensuring optimal performance and efficient resource usage. These insights help proactively address issues, supporting informed decision-making and streamlined operations.

## Benefits

Monitoring open-source, fine-tuned, commercial, or custom API models offers the following benefits:

* **Detailed Analysis**: Model Tracing allows an in-depth analysis of the model’s performance across all handled requests, enabling review of inputs, generated outputs, and associated run-based metadata.
* **Optimization**: Regular monitoring helps track key metrics like total requests, failure rates, response times, input, output, and credit consumption to ensure optimal model performance over time.
* **Cost Management**: Monitoring total requests and consumed credits (Host Credits) enables analysis of failure trends, consumption spikes, and alignment with expected outcomes, providing improved cost visibility and control.
* **Scalability**: Usage data from monitored runs reveals performance patterns for improved model scalability.
* **Compliance and Security**: Tracking models across multiple requests helps ensure that input and output data handling is secure, ethical, and regulated.
* **Troubleshooting and Maintenance**: Tracking errors and failures across runs using request metadata and JSON code helps identify and troubleshoot issues, inefficiency, and interruptions.

## Key Features

* **Column Filters** enable you to view specific records by setting a column value or combining multiple filters using AND/OR operators. [Learn more](./model-traces.md/#filter-model-traces-by-columns){:target="_blank"}.
* **Time-based filters** provide a comprehensive view of the selected model's performance across runs for a specific past date or date range. [Learn more](./model-traces.md/#time-based-filters){:target="_blank"}.
* **Search** lets you look up a specific run(s) of a model using the *Request ID* and other *String* type column values.
* Hovering over specific metrics displays a tooltip that provides additional information about the metric's purpose and significance.
* When selecting a date range filter, you can obtain **hourly performance analysis** for a model on a specific day or review **daily performance trends**.
* Click the **Visibility Filter** icon shown below to add or remove the selected column(s) from the table view of records. Turn on the toggle to add a column and turn it off to remove it.
<img src="../images/visibility-icon.png" alt="visibility icon" title="visibility icon" style="border: 1px solid gray; zoom:75%;">
* Successful requests are marked with a **green check icon**, while failed requests are marked with a **red alert icon**.
<img src="../images/success-failed-requests.png" alt="success and failed requests" title="success and failed requests" style="border: 1px solid gray; zoom:75%;">

* Export the model traces dataset for your model into a CSV file for further analysis, editing, and debugging.
* The **Metrics Summary** showcases the key performance metrics of the selected model across all executed runs. [Learn more](./model-traces.md/#performance-metrics-summary){:target="_blank"}.
* The **table view** summarizes key metadata for successful and failed runs of the selected model, offering quick insights and the ability to monitor run-specific response times, analyze input and output, view failed runs in detail, and verify whether credit consumption aligns with usage. 
* Click the **Sort** filter in the **Executed on** column to view the data in ascending or descending order by execution date.
<img src="../images/model-traces-sort.png" alt="model traces sort" title="model traces sort" style="border: 1px solid gray; zoom:75%;">

* Click on each model traces record in the table to view the input, output, and key metadata. [Learn more](./model-traces.md/#traces-input-output-and-metadata){:target="_blank"}.

## Best Practices

* Track the **Total Requests** versus **Hosting Credits** for fine-tuned and open-source models created, deployed, and monitored on GALE to optimize usage.
* Analyze successful versus failed runs to compare model performance over time and identify failure patterns using failure rates for all model types.
* Identify model runs with low or high response times using P90 and P99 thresholds and isolate under-performing runs for further investigation.
* Apply time-based and record filters for focused and accurate analysis.
* Analyze the input for each request, the output generated by the model, the response time, and the source or module from which the request originated. This analysis supports performance insights, error diagnosis, source identification, and optimization of usage and user experience.
* View, copy, and edit input and output text or JSON code to enhance understanding and facilitate troubleshooting of the model run.
* Perform model tracing using run-specific metadata, including the base model used, response time, input and output token counts, request source information, and the name of the account user who executed the run.

## Access Model Traces 

To access the **Model Traces**, follow the steps below:

1. [Navigate](../../settings-overview.md/#access-settings-console){:target="_blank"} to the **Settings** Console.
2. On the left menu, select **Monitoring** > **Model Traces**.
3. If this is your first time accessing the feature, select the desired model from the dropdown menu shown below.
<img src="../images/get-started-model-traces.png" alt="get started with model traces" title="get started with model traces" style="border: 1px solid gray; zoom:75%;">

The system loads the **Model Traces** feature with data for the last 30 days, which is the default time range selection. 

If you have used the feature before, the data from your previous model selection is loaded for 30 days (the default selection).
<img src="../images/preload-model-traces-data.png" alt="preload model traces data" title="preload model traces data" style="border: 1px solid gray; zoom:75%;">

## Model Traces Information

**Model Traces** in the **Settings** console provides a centralized view for actionable insights into run-level details of the selected model deployed in your account.

The key features for customizing the model traces data include:

* **Model Name Filter**: Required for selecting and viewing information specific to the model you want to monitor.
<img src="../images/model-name-filter.png" alt="model name filter" title="model name filter" style="border: 1px solid gray; zoom:75%;">

* **Time Selection Filter**: Required to analyze model traces data for a specific time-frame in the past. [Learn more](./model-traces.md/#time-based-filters){:target="_blank"}.
* **Filter By Option**: An optional multi-field, multi-level filter for targeted analysis. [Learn more](./model-traces.md/#filter-model-traces-by-columns){:target="_blank"}.
* **Visibility Filter**: Add or remove columns from the UI to display only relevant data. To set the filter, click the **Eye** icon, enable the field to view its data, and disable it otherwise.
<img src="../images/visibility-filter.png" alt="visibility filters" title="visibility filters" style="border: 1px solid gray; zoom:75%;">

<div class="admonition note">
<p class="admonition-title">Note</p>
<p><ul><li>By default, all the columns are visible in the table.</li>
<li>You can adjust visibility for 8 columns in open-source and fine-tuned models and 7 columns for other model types.</li>
<li>The <b>Deployment Type</b> filter is available only for open-source and fine-tuned models, not for external or custom API types.</li></ul></p></div>

<ul><li><b>Export Data</b>: Click <b>Export</b> to generate a <i>CSV</i> file of your model traces records based on the selected date range and filters. Note that all eight columns in the table are prepared and exported, irrespective of the applied visibility filter.</li>
<img src="../images/click-export.png" alt="export" title="export" style="border: 1px solid gray; zoom:75%;"></ul>

The progress status is displayed in the UI when preparing and exporting data.
<img src="../images/export-progress-status.png" alt="export progress" title="export progress" style="border: 1px solid gray; zoom:75%;">

Once the file is downloaded, the following message is displayed.
<img src="../images/export-model-traces-success.png" alt="export success" title="export success" style="border: 1px solid gray; zoom:75%;">

If any error occurs during the export process, the following message is displayed:
<img src="../images/export-failed-notification.png" alt="export error" title="export error" style="border: 1px solid gray; zoom:75%;">

Below is a sample of the export schema file. The file name is automatically saved in the format <code>modelname_traces_data</code>, such as <code>GPT4_traces_data</code>.
<img src="../images/export-schema.png" alt="export schema" title="export schema" style="border: 1px solid gray; zoom:75%;">

<div class="admonition note">
<p class="admonition-title">Key Considerations</p>
<p><ul><li>Each user’s export process is implemented separately, ensuring that one user's cancellations or adjustments do not interfere with another user’s export pipeline.</li>
<li>Users can cancel an ongoing export operation, if required.</li></ul></p></div>

* **Search**: You can locate specific model traces records on the UI by entering the run's *Request* *ID* in the **Search** textbox. The system returns matching results, as shown below.
<img src="../images/search-record-model-traces.png" alt="search model traces record" title="search model traces record" style="border: 1px solid gray; zoom:75%;">

* **Model Performance Metrics Summary**: Summarizes key metrics to help quickly analyze the model’s performance. [Learn more](./model-traces.md/#performance-metrics-summary){:target="_blank"}.
* **Model Traces**: The table displays all runs executed by the model since its configuration, sorted by execution date from the latest to the oldest records. It includes data from the initial execution onward—whether deployed (for open-source and fine-tuned models) or integrated (for external models). The table includes the following metrics:
    * **Status**: An icon indicating the success or failure of the run is displayed. See point 7 [here](./model-traces.md/#key-features){:target="_blank"}.
    * **Request ID**: The unique identifier used for the run record. 
    * **Response Time**: The time taken by the model to respond to a request.
    * **Deployment Version**: The model version deployed in your account. 
    * **Source Type**: The source type that initiated the request. 
    * **Source**: The source name from where the request was initiated.

Please refer to the table [here](./model-traces.md/#steps-to-add-a-custom-filter){:target="_blank"} for more information on the above metrics.

* **Executed on**: The run execution timestamp, with records displayed from latest to oldest by date.
* **Input**: Displays the input text provided for the run execution.
* **Output**: Displays the output text generated or response after the run.

To view the detailed trace information, click the required record.
<img src="../images/detailed-trace-information.png" alt="click traces record" title="click traces record" style="border: 1px solid gray; zoom:75%;">

## Performance Metrics Summary

The UI summarizes key metrics for the selected period, offering actionable insights into the deployed model’s performance. 

* **Total Requests**: The total number of requests/runs serviced by the model since its deployment in your account. The metric reflects an LLM model's processing speed and efficiency, helping identify performance issues and optimize responsiveness.
* **Response Time**: P90 and P99 response times show the thresholds below which 90% and 99% of responses fall, indicating model consistency. Lower values reflect reliable speed, while higher values suggest performance issues. For example,
    * If a model's P90 is 100 seconds, it means that 99% of the requests are completed within 100 seconds.
    * If a model's P99 is 100 seconds, it means that 99% of the requests are completed within 100 seconds.
* **Failure Rate**: Indicates the number of requests/runs that failed with an error code or were not serviced by the model out of the total requests sent since deployment. For example, if 5 requests failed out of 100, the failure rate displayed is 5%.
* **Hosting Credits**: Displays the credits consumed in your account by the deployed model based on its usage. Please see the pricing details [here](../../../models/hardware-pricing.md){:target="_blank"}. This metric allows for a comparison of credit consumption against actual model usage.

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Hosting Credits apply only to GALE’s open-source and fine-tuned models and are not displayed for external models.</p></div>

<img src="../images/hosting-credits.png" alt="hosting credits" title="hosting credits" style="border: 1px solid gray; zoom:75%;">

## Time-based Filters

Use the time selection filter to view and monitor model traces across runs within a specific period. This allows you to focus on requests within a set time-frame to track changes or perform targeted debugging.

<div class="admonition note">
<p class="admonition-title">Note</p>
<p><ul><li><b>Last 30 Days</b> is the default selection, which displays data for the past 30 days from the current date.</li>
<li>Data is displayed only if requests/runs were executed by the selected model during the selected period.</li></ul></p></div>

Time selection is available for the past and current period, including the ones listed below:

<ul><li><b>All Time</b>: Displays the runs' data since the time the account was created.</li>
<li><b>Today</b>: Includes data generated on the current day.</li>
<li><b>Today</b>: Includes data generated on the current day.</li>
<li><b>Yesterday</b>: Includes data generated on the previous day.</li>
<li><b>This Week</b>: Displays data for all the days in the current week.</li>
<li><b>This Month</b>: Displays data for all the days in the current month.</li>
<li><b>Last Month</b>: Displays data for all the days in the previous month.</li>
<li><b>Last 30 Days</b>: Displays data for the past 30 days from the current date.</li>
<li><b>Last 90 Days</b>: Displays logs for the past 90 days from the current date.</li>
<li><b>This Year</b>: Displays logs for all the days in the current year.</li>
<li><b>Last Year</b>: Displays logs for all the days in the past year.</li></ul>

### Steps to Set Time Range for Model Traces

1. [Navigate](../analytics/model-traces.md/#access-model-traces){:target="_blank"} to the **Model Traces** feature.
2. Click the time selection button (displays **Last 30 Days**).
<img src="../images/time-selection-button.png" alt="time selection button" title="time selection button" style="border: 1px solid gray; zoom:75%;">

3. Select the required period on the left panel, or select a specific date, month, or year on the calendar widget (the current day is the default selection).
4. Click **Apply**.
<img src="../images/select-and-apply.png" alt="select date" title="select date" style="border: 1px solid gray; zoom:75%;">

The relevant model traces' data is displayed for the selected period.

### Key Considerations and Tips

The date range is automatically selected on the calendar widget once you select the period and displayed at the bottom of the widget.
<img src="../images/date-range-display.png" alt="date range display" title="date range display" style="border: 1px solid gray; zoom:75%;">

You can select a specific month or year from the relevant dropdown list and switch to different months by clicking the **forward/backward** arrows.
<img src="../images/calendar-widget.png" alt="calendar widget" title="calendar widget" style="border: 1px solid gray; zoom:75%;">

To set a specific past date as the start date, click on the desired date in the widget.

By default, the current day will be set as the end date. This feature allows you to easily customize the period you want to monitor and analyze model traces.
<img src="../images/default-calendar-selection.png" alt="default selection" title="default selection" style="border: 1px solid gray; zoom:75%;">

## Filter Model Traces by Columns

You can narrow down the information displayed for model traces by applying **custom column filters**. This functionality is similar to **Filter** in the Audit Logs feature. [Learn more](../audit-logs.md/#filter-audit-logs){:target="_blank"}.

These filters allow you to select specific column values, compare the chosen or entered values, and apply logical operators across columns for multi-level filtering, providing targeted, custom data on the UI.

Filter customization streamlines tracking and debugging of model runs at a detailed level, enhancing user experience.

### Steps to Add a Custom Filter

1. [Navigate](./model-traces.md/#access-model-traces){:target="_blank"} to the **Model Traces** feature.
2. Click the **Filter** icon.
3. Click **+ Add Filter**.
<img src="../images/click-add-filter.png" alt="add filter" title="add filter" style="border: 1px solid gray; zoom:75%;">

4. In the **Filter By** window, select the required option from the **Select** **Column**, **Operator**, and **Value** dropdown lists. For specific column filters, you must enter the value manually.
<img src="../images/filter-selection-model-traces.png" alt="filter selection" title="filter selection" style="border: 1px solid gray; zoom:75%;">

The table below summarizes the available columns along with their supported operators and values. 

<table>
  <tr>
   <td>
<strong>Column Name</strong>
   </td>
   <td><strong>Description</strong>
   </td>
   <td><strong>Comparison Operator</strong>
   </td>
   <td><strong>Input Type for Value</strong>
   </td>
   <td><strong>Value Options</strong>
   </td>
  </tr>
  <tr>
   <td rowspan="2" ><strong>Status</strong>
   </td>
   <td rowspan="2" >Indicates the status of the model’s executed run. 
   </td>
   <td>Is Equals To
   </td>
   <td rowspan="2" >List Selection
   </td>
   <td rowspan="2" >
<ul>
<li><strong>Failed</strong>: Indicates failed runs.</li>
<li><strong>Success</strong>: Indicates successful runs.</li>
</ul>
   </td>
  </tr>
  <tr>
   <td>Is Not Equals To
   </td>
  </tr>
  <tr>
   <td rowspan="3" ><strong>Request ID</strong>
   </td>
   <td rowspan="3" >The unique ID associated with the model run/request.
   </td>
   <td>Is Equals To
   </td>
   <td rowspan="3" >Enter manually
   </td>
   <td rowspan="3" >Any value
   </td>
  </tr>
  <tr>
   <td>Is Not Equals To
   </td>
  </tr>
  <tr>
   <td>Contains
   </td>
  </tr>
  <tr>
   <td rowspan="6" ><strong>Response Time</strong>
   </td>
   <td rowspan="6" >The response time of the model for the executed request.
   </td>
   <td>Is Equals To
   </td>
   <td rowspan="6" >Enter manually
   </td>
   <td rowspan="6" >Enter the numeric values for minutes,  seconds, and milliseconds in the m:s:ms format.
   </td>
  </tr>
  <tr>
   <td>Is Not Equals To
   </td>
   </tr>
  <tr>
   <td>Is Greater Than
   </td>
  </tr>
  <tr>
   <td>Is Less Than
   </td>
  </tr>
  <tr>
   <td>Is Greater Than Equals To
   </td>
  </tr>
  <tr>
   <td>Is Less Than Equals To
   </td>
  </tr>
  <tr>
   <td rowspan="3" ><strong>Deployment Version</strong>
   </td>
   <td rowspan="3" >The version of the model deployed for the specific run.
   </td>
   <td>Is Equals To
   </td>
   <td rowspan="3" >Enter manually
   </td>
   <td rowspan="3" >Any value
   </td>
  </tr>
  <tr>
   <td>Is Not Equals To
   </td>
  </tr>
  <tr>
   <td>Contains
   </td>
  </tr>
  <tr>
   <td rowspan="3" ><strong>Source Type</strong>
   </td>
   <td rowspan="3" >The source type from which the run request was sent to the model.
   </td>
   <td>Is Equals To
   </td>
   <td rowspan="3" >List Selection
   </td>
   <td rowspan="3" >
<ul>

<li><strong>Agent</strong>: The request was sent to the model from an agent. <a href="https://docs.kore.ai/gale/agents/overview/" target="_blank">Learn more</a>.</li>

<li><strong>Prompts</strong>: The request was sent to the model from a Prompt experiment. <a href="https://docs.kore.ai/gale/playground/using-prompt-studio/" target="_blank">Learn more</a>.</li>

<li><strong>API Key</strong>: The request was sent to the (open-source) model using an API key. <a href="https://docs.kore.ai/gale/models/open-source-models/generate-an-api-key-open-source/" target="_blank">Learn more</a>.</li>
</ul>
   </td>
  </tr>
  <tr>
   <td>Is Not Equals To
   </td>
  </tr>
  <tr>
   <td>Contains
   </td>
  </tr>
  <tr>
   <td rowspan="3" ><strong>Source</strong>
   </td>
   <td rowspan="3" >The source from which the model received the run request.
   </td>
   <td>Is Equals To
   </td>
   <td rowspan="3" >List Selection
   </td>
   <td rowspan="3" >Custom value(s) set by the user.
   </td>
  </tr>
  <tr>
   <td>Is Not Equals To
   </td>
  </tr>
  <tr>
   <td>Contains
   </td>
  </tr>
</table>

<ol start="5"><li>Click <b>Apply</b>.</li>
<img src="../images/apply-filter-model-traces.png" alt="apply filter" title="apply filter" style="border: 1px solid gray; zoom:75%;"></ol>

The UI displays all the relevant model traces' records that align with the applied filter(s). The number of filters you have applied is displayed on the **Filter** icon.
<img src="../images/number-of-filters.png" alt="number of filters" title="number of filters" style="border: 1px solid gray; zoom:75%;">

To clear the filter settings, click **Clear All**.

<img src="../images/clear-all-link.png" alt="clear all" title="clear all" style="border: 1px solid gray; zoom:75%;">

### Add Multiple Filters

Adding multiple filter levels enhances model trace visibility on the UI. You can combine column, operator, and value filters using the AND or OR operators for targeted data, allowing you to focus on the model trace entries most relevant to your needs. [Learn more](../audit-logs.md/#add-multiple-filters){:target="_blank"}.

**Important**

* AND and OR operators cannot be combined in multiple filtering steps to set filter criteria, ensuring consistent operator usage for each filtering step.
* Using the AND operator ensures that all specified conditions must be met for an entry to be included in the results.
* On the other hand, using the OR operator broadens the criteria, allowing entries that meet any of the specified conditions to be included. These operators provide flexibility in tailoring your model traces data.
* Click the **Delete** icon to delete a filter criteria step.
<img src="../images/delete-filter-icon.png" alt="delete filter" title="delete filter" style="border: 1px solid gray; zoom:75%;">

#### Steps to Add Multiple Filters

1. Follow **Steps 1 to 3** mentioned [here](./model-traces.md/#steps-to-add-a-custom-filter){:target="_blank"}.
2. Select the **AND/OR** operator tab in the **Filter by** window.

    <img src="../images/select-operator-filter.png" alt="select operator" title="select operator" style="border: 1px solid gray; zoom:75%;">

3. Follow **Steps 4 to 5** mentioned [here](./model-traces.md/#steps-to-add-a-custom-filter){:target="_blank"}.

The matched model traces entries are displayed in the UI.

## Traces: Input, Output and Metadata

Clicking on a run/request record on the UI opens the detailed **Traces** window displaying the Request ID and the following information:

### Input and Output Panels

* The **Input** panel displays the request (text) provided to the model using input tokens to execute the request.
* The **Output** panel displays the text output or response generated by the model using output tokens after the run execution.

**Key Considerations**

* Plain text is the default display format.
<img src="../images/plaintext-editor-display.png" alt="plaintext editor" title="plaintext editor" style="border: 1px solid gray; zoom:75%;">

* Enabling JSON mode allows you to access the JSON view of the input in the editor. This view provides the complete response/request payload sent to the model, including additional keys and details not visible in plain text format.
* The text and JSON code cannot be modified in the editor.
<img src="../images/json-editor-model-traces.png" alt="json editor" title="json editor" style="border: 1px solid gray; zoom:75%;">

* Click the **Copy** icon to copy the text or code and paste it into your preferred editor for debugging or troubleshooting.
<img src="../images/copy-input.png" alt="copy input" title="copy input" style="border: 1px solid gray; zoom:75%;">

* The key metadata related to the processed request is shown in a separate window.
<img src="../images/model-traces-windows.png" alt="model traces window" title="model traces window" style="border: 1px solid gray; zoom:75%;">

* Click the **Up** and **Down** buttons to navigate through request records.
<img src="../images/navigate-model-traces-records.png" alt="navigate model traces" title="navigate model traces" style="border: 1px solid gray; zoom:75%;">

### Metadata Panel

Displays the following model run metadata to analyze the model’s performance.

* **Request ID**: Unique identifier for the specific model request.
* **Base model**: The Kore-hosted or imported model that executes the request.
* **Deployment version**: Version of the model deployed for the run.
* **Response time**: Time taken by the model to generate a response.
* **Input tokens**: Number of tokens in the request input.
* **Output tokens**: Number of tokens in the model’s response.
* **Executed on**: Date and time when the run was executed.
* **Source type**: Type of source that sent the request.
* **Source**: Specific origin of the request.
* **User ID**: Identifier for the user who initiated the request.

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Deployment Version is displayed only for GALE's open-source and fine-tuned models, not for external models.</p></div>

<img src="../images/meta-data-model-traces.png" alt="metadata" title="metadata" style="border: 1px solid gray; zoom:75%;">

**Model Traces** empowers users to identify time-based trends, troubleshoot issues, and make informed decisions by offering detailed and targeted insights into run-based metrics. This capability ensures that organizations uphold high efficiency, reliability, and compliance standards in their model deployments.

## Related Information

* [Settings Console](../../settings-overview.md){:target="_blank"}- Learn more about other GALE admin features.
* [Monitoring: Model Analytics Dashboard](../analytics/model-analytics-dashboard.md){:target="_blank"}- Get actionable insights into model-specific metrics and optimize performance.
* [Monitoring: Audit Logs](../audit-logs.md){:target="_blank"}- Track activities and events in your account.
* [Billing](../../billing/billing-and-usage.md){:target="_blank"}- Manage resource consumption for agents, set limits, and track usage trends.

